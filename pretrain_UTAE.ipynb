{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sl221120/anaconda3/envs/fire_ts/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sl221120/anaconda3/envs/fire_ts/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sl221120/anaconda3/envs/fire_ts/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from src.models.utae_paps_models.utae import UTAE\n",
    "import torchvision.models as models\n",
    "\n",
    "resnet = models.resnet34(pretrained=True)\n",
    "\n",
    "utae = UTAE(\n",
    "            input_dim=7,\n",
    "            encoder_widths=[64, 64, 64, 128],\n",
    "            decoder_widths=[32, 32, 64, 128],\n",
    "            out_conv=[32, 1],\n",
    "            str_conv_k=4,\n",
    "            str_conv_s=2,\n",
    "            str_conv_p=1,\n",
    "            agg_mode=\"att_group\",\n",
    "            encoder_norm=\"group\",\n",
    "            n_head=16,\n",
    "            d_model=256,\n",
    "            d_k=4,\n",
    "            encoder=False,\n",
    "            return_maps=False,\n",
    "            pad_value=0,\n",
    "            padding_mode=\"reflect\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UTAE(\n",
       "  (in_conv): ConvBlock(\n",
       "    (conv): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "        (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "        (4): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0-1): 2 x DownConvBlock(\n",
       "      (down): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv1): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): DownConvBlock(\n",
       "      (down): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv1): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpConvBlock(\n",
       "      (skip_conv): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (up): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv1): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): UpConvBlock(\n",
       "      (skip_conv): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (up): Sequential(\n",
       "        (0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv1): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): UpConvBlock(\n",
       "      (skip_conv): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (up): Sequential(\n",
       "        (0): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv1): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_encoder): LTAE2d(\n",
       "    (inconv): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "    (positional_encoder): PositionalEncoder()\n",
       "    (attention_heads): MultiHeadAttention(\n",
       "      (fc1_k): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (attention): ScaledDotProductAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=2)\n",
       "      )\n",
       "    )\n",
       "    (in_norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
       "    (out_norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (temporal_aggregator): Temporal_Aggregator()\n",
       "  (out_conv): ConvBlock(\n",
       "    (conv): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "        (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet layer1 conv1 shape: torch.Size([64, 64, 3, 3])\n",
      "UTAE down_blocks[0] conv1 shape: torch.Size([64, 64, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"ResNet layer1 conv1 shape:\", resnet.layer1[0].conv1.weight.shape)\n",
    "print(\"UTAE down_blocks[0] conv1 shape:\", utae.down_blocks[0].conv1.conv[0].weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def load_resnet_weights_to_utae(resnet, utae_model):\n",
    "    loaded_layers = 0\n",
    "    loaded_weights = []\n",
    "\n",
    "    # Mapping resnet layers to UTAE down_blocks\n",
    "    resnet_layer1 = resnet.layer1  # Equivalent to down_blocks[0] and down_blocks[1] in UTAE\n",
    "    resnet_layer2 = resnet.layer2  # Equivalent to down_blocks[2] in UTAE\n",
    "\n",
    "    # Transfer weights from ResNet's layer1 to UTAE down_blocks[0] and down_blocks[1]\n",
    "    for i in range(2):  # down_blocks[0] and down_blocks[1]\n",
    "        res_block = resnet_layer1[i]  # ResNet BasicBlock\n",
    "        utae_block = utae_model.down_blocks[i]  # UTAE DownConvBlock\n",
    "\n",
    "        # Skip the 'down' ConvLayer in UTAE since it's not equivalent\n",
    "        # Load weights for conv1\n",
    "        if res_block.conv1.weight.shape == utae_block.conv1.conv[0].weight.shape:\n",
    "            utae_block.conv1.conv[0].weight.data = res_block.conv1.weight.data\n",
    "            print(f\"ResNet layer: layer1[{i}].conv1 --> UTAE layer: down_blocks[{i}].conv1\")\n",
    "            loaded_weights.append(f'down_blocks[{i}].conv1')\n",
    "            loaded_layers += 1\n",
    "            if hasattr(res_block.conv1, \"bias\") and res_block.conv1.bias is not None:\n",
    "                utae_block.conv1.conv[0].bias.data = res_block.conv1.bias.data\n",
    "\n",
    "        # Load weights for conv2\n",
    "        if res_block.conv2.weight.shape == utae_block.conv2.conv[0].weight.shape:\n",
    "            utae_block.conv2.conv[0].weight.data = res_block.conv2.weight.data\n",
    "            print(f\"ResNet layer: layer1[{i}].conv2 --> UTAE layer: down_blocks[{i}].conv2\")\n",
    "            loaded_weights.append(f'down_blocks[{i}].conv2')\n",
    "            loaded_layers += 1\n",
    "            if hasattr(res_block.conv2, \"bias\") and res_block.conv2.bias is not None:\n",
    "                utae_block.conv2.conv[0].bias.data = res_block.conv2.bias.data\n",
    "\n",
    "    # Transfer weights from ResNet's layer2 to UTAE down_blocks[2]\n",
    "    res_block = resnet_layer2[0]  # First block in layer2\n",
    "    utae_block = utae_model.down_blocks[2]  # UTAE DownConvBlock for layer2 equivalent\n",
    "\n",
    "    # Skip the 'down' ConvLayer in UTAE since it has different stride and kernel size\n",
    "    # Load weights for conv1 (64 -> 128)\n",
    "    if res_block.conv1.weight.shape == utae_block.conv1.conv[0].weight.shape:\n",
    "        utae_block.conv1.conv[0].weight.data = res_block.conv1.weight.data\n",
    "        print(f\"ResNet layer: layer2[0].conv1 --> UTAE layer: down_blocks[2].conv1\")\n",
    "        loaded_weights.append(f'down_blocks[2].conv1')\n",
    "        loaded_layers += 1\n",
    "        if hasattr(res_block.conv1, \"bias\") and res_block.conv1.bias is not None:\n",
    "            utae_block.conv1.conv[0].bias.data = res_block.conv1.bias.data\n",
    "\n",
    "    # Load weights for conv2 (128 -> 128)\n",
    "    if res_block.conv2.weight.shape == utae_block.conv2.conv[0].weight.shape:\n",
    "        utae_block.conv2.conv[0].weight.data = res_block.conv2.weight.data\n",
    "        print(f\"ResNet layer: layer2[0].conv2 --> UTAE layer: down_blocks[2].conv2\")\n",
    "        loaded_weights.append(f'down_blocks[2].conv2')\n",
    "        loaded_layers += 1\n",
    "        if hasattr(res_block.conv2, \"bias\") and res_block.conv2.bias is not None:\n",
    "            utae_block.conv2.conv[0].bias.data = res_block.conv2.bias.data\n",
    "\n",
    "    print(f\"Total layers loaded: {loaded_layers}\")\n",
    "    print(\"Loaded weights:\")\n",
    "    for weight in loaded_weights:\n",
    "        print(weight)\n",
    "\n",
    "# Example usage:\n",
    "# resnet = torchvision.models.resnet34(pretrained=True)\n",
    "# load_resnet_weights_to_utae(resnet, utae_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet layer: layer1[0].conv1 --> UTAE layer: down_blocks[0].conv1\n",
      "ResNet layer: layer1[0].conv2 --> UTAE layer: down_blocks[0].conv2\n",
      "ResNet layer: layer1[1].conv1 --> UTAE layer: down_blocks[1].conv1\n",
      "ResNet layer: layer1[1].conv2 --> UTAE layer: down_blocks[1].conv2\n",
      "ResNet layer: layer2[0].conv1 --> UTAE layer: down_blocks[2].conv1\n",
      "ResNet layer: layer2[0].conv2 --> UTAE layer: down_blocks[2].conv2\n",
      "Total layers loaded: 6\n",
      "Loaded weights:\n",
      "down_blocks[0].conv1\n",
      "down_blocks[0].conv2\n",
      "down_blocks[1].conv1\n",
      "down_blocks[1].conv2\n",
      "down_blocks[2].conv1\n",
      "down_blocks[2].conv2\n"
     ]
    }
   ],
   "source": [
    "# Initialize UTAE model\n",
    "utae_model = UTAE(input_dim=7)\n",
    "\n",
    "# Load pretrained ResNet\n",
    "resnet = models.resnet34(pretrained=True)\n",
    "\n",
    "# load weights:\n",
    "load_resnet_weights_to_utae(resnet, utae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "random_input = torch.randn(1, 5, 7, 128, 128)  \n",
    "batch_positions = torch.arange(5).unsqueeze(0).repeat(1, 1) \n",
    "\n",
    "utae_model.eval()  \n",
    "with torch.no_grad(): \n",
    "    output = utae_model(random_input, batch_positions)\n",
    "\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loaded_percentage_in_encoder(resnet, utae_model):\n",
    "    total_params = 0\n",
    "    loaded_params = 0\n",
    "\n",
    "    # Mapping resnet layers to UTAE down_blocks\n",
    "    resnet_layer1 = resnet.layer1  # Equivalent to down_blocks[0] and down_blocks[1] in UTAE\n",
    "    resnet_layer2 = resnet.layer2  # Equivalent to down_blocks[2] in UTAE\n",
    "\n",
    "    # For down_blocks[0] and down_blocks[1], matching ResNet's layer1\n",
    "    for i in range(2):  # down_blocks[0] and down_blocks[1]\n",
    "        res_block = resnet_layer1[i]  # ResNet BasicBlock\n",
    "        utae_block = utae_model.down_blocks[i]  # UTAE DownConvBlock\n",
    "\n",
    "        # Total parameters in UTAE conv1 and conv2\n",
    "        total_params += utae_block.conv1.conv[0].weight.numel()\n",
    "        total_params += utae_block.conv2.conv[0].weight.numel()\n",
    "\n",
    "        # Check if ResNet weights can be loaded\n",
    "        if res_block.conv1.weight.shape == utae_block.conv1.conv[0].weight.shape:\n",
    "            loaded_params += res_block.conv1.weight.numel()\n",
    "        if res_block.conv2.weight.shape == utae_block.conv2.conv[0].weight.shape:\n",
    "            loaded_params += res_block.conv2.weight.numel()\n",
    "\n",
    "    # For down_blocks[2], matching ResNet's layer2\n",
    "    res_block = resnet_layer2[0]  # First block in layer2\n",
    "    utae_block = utae_model.down_blocks[2]  # UTAE DownConvBlock for layer2 equivalent\n",
    "\n",
    "    # Total parameters in UTAE conv1 and conv2\n",
    "    total_params += utae_block.conv1.conv[0].weight.numel()\n",
    "    total_params += utae_block.conv2.conv[0].weight.numel()\n",
    "\n",
    "    # Check if ResNet weights can be loaded\n",
    "    if res_block.conv1.weight.shape == utae_block.conv1.conv[0].weight.shape:\n",
    "        loaded_params += res_block.conv1.weight.numel()\n",
    "    if res_block.conv2.weight.shape == utae_block.conv2.conv[0].weight.shape:\n",
    "        loaded_params += res_block.conv2.weight.numel()\n",
    "\n",
    "    # Compute the percentage of weights loaded\n",
    "    percentage_loaded = (loaded_params / total_params) * 100\n",
    "    print(f\"Total weights in encoder: {total_params}\")\n",
    "    print(f\"Loaded weights in encoder: {loaded_params}\")\n",
    "    print(f\"Percentage of weights loaded in encoder: {percentage_loaded:.2f}%\")\n",
    "\n",
    "# Example usage:\n",
    "# resnet = torchvision.models.resnet34(pretrained=True)\n",
    "# calculate_loaded_percentage_in_encoder(resnet, utae_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total weights in encoder: 368640\n",
      "Loaded weights in encoder: 368640\n",
      "Percentage of weights loaded in encoder: 100.00%\n"
     ]
    }
   ],
   "source": [
    "calculate_loaded_percentage_in_encoder(resnet, utae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
